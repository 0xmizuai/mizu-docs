---
title: 'Data Repo'
description: 'Open, collaborative and permissionless'
icon: 'layer-group'
---

## From Open Source Code to Open Source Data

MIZU aims to build an open, collaborative, and permissionless data ecosystem that empowers AI developers to create diverse AI applications and supports fully open Large Language Models (LLMs) by providing public, risk-free data recipes. We call it "open source data."

There are tons of open-sourced datasets out there today, e.g., CommonCrawl, HuggingFace. However, these datasets are static, which has the following drawbacks:
- There is no way to contribute to the datasets.
- It's hard to measure the data quality.
- It's hard to compose new datasets based on existing ones.

What if we can collaborate on top of a dataset just like working against a GitHub repo? This is what MIZU is building right now. We are transforming static datasets into open, collaborative, and permissionless data repos where anyone can contribute.

## The Data Repo

The data repo is composed of the following four pieces:

- **Smart Account**: Each data repo is managed by a smart contract, allowing it to hold tokens and giving users permissions to manage the data and rules. The smart account serves as the foundation for the repo's governance and access control.

- **Datasets**: This is the actual data committed to the repo. The datasets can be in various formats and cover a wide range of domains, providing the raw material for AI applications and models.

- **Data Index**: The data index provides specific views of the data, which can be subsets of the data or aggregated results. A validation rule can be applied to either the data or the data index, ensuring the quality and consistency of the information accessible through the index.

- **Validation Rules**: The validation rules define what data can be committed to the repo. These rules can be descriptive, which will be validated by Large Language Models (LLMs), or program-based, which will be validated by pre-compiled validators. The validation rules ensure the integrity and reliability of the data within the repo.

### Governance

The governance of the repo is designed to be flexible and adaptable. The validation rules can be updated according to the permission setup defined in its smart account. The more comprehensive the validation rules are, the higher the quality of the final data repo. This allows the community to continuously refine and improve the data governance processes.

## The End-to-End User Journey

### Step 1: Data Consumers Create a Repo and Define Validation Rules

Data consumers initiate the process by creating a new data repo and describing the validation rules that will govern the data within it. These rules set the standards for data quality, format, and content, ensuring that the repo maintains its integrity and usefulness.

### Step 2: Community Members Build Proper Prompts for Data Generation

The community plays a crucial role in building appropriate prompts for data generation. These prompts guide the data creation process, ensuring that the generated data aligns with the repo's purpose and meets the validation rules.

### Step 3: MIZU Data Network Generates, Validates, and Commits Data

The MIZU Data Network takes the prompts created by the community and generates data accordingly. The generated data is then validated against the repo's validation rules. Only data that passes the validation process is committed to the repository, ensuring that the repo maintains a high level of data quality.

Through this end-to-end user journey, MIZU creates a collaborative and efficient process for building high-quality, open-source data repositories that can power the next generation of AI applications and models.
<img
  className="block dark:hidden"
  src="/images/data-repo-light.png"
  alt="Hero Light"
/>
<img
  className="hidden dark:block"
  src="/images/data-repo-dark.png"
  alt="Hero Dark"
/>
