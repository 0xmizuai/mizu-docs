---
title: 'Why MIZU'
description: 'MIZU aims to solve the data scarcity and data monopoly problem by combining Web3 and synthetic data.'
icon: 'code'
---

## Why Synthetic Data

In the AI industry, data has always been a crucial component for training and developing robust models. Prior to the advent of GPT-4, the primary challenge faced by AI model developers was not the availability of data, but rather the interpretation of that data. The internet provided an abundant source of information that could be easily crawled and collected. As a result, numerous data crawling and data labeling companies emerged to assist in the process of transforming raw data into structured, labeled datasets that could be used for training AI models. However, the AI landscape has undergone a significant shift after GPT-4. The vast majority of real-world data has already been utilized, and finding new, diverse, and relevant data sources has become increasingly difficult. This scarcity of data poses a significant obstacle for the continued development and improvement of AI models.

__To address the issue of data scarcity, the AI industry has turned to a practice known as data farming.__ Data farming involves actively cultivating and generating new data specifically designed for training AI models. This approach goes beyond simply collecting existing data and instead focuses on creating novel datasets tailored to the specific needs of the AI system being developed. Examples of data farming include creating virtual environments and simulations to generate synthetic data, conducting targeted surveys or experiments to gather new insights, and using generative models to produce realistic but artificial data samples.

Among the various data farming techniques, synthetic data generation has emerged as one of the most promising solutions to the data scarcity problem. Synthetic data refers to artificially created data that mimics the characteristics and patterns of real-world data. It is generated using algorithms and models that learn from existing datasets and then produce new, realistic samples that can be used for training AI models. Synthetic data offers several advantages, such as the ability to generate large volumes of data quickly, the flexibility to create data with specific desired properties, and the potential to overcome privacy concerns associated with using real-world data.

Synthetic data generation has shown promising results in various domains, including computer vision, natural language processing, and robotics. For example, in computer vision, synthetic images can be generated to augment existing datasets, providing additional training examples for object detection, segmentation, and classification tasks. In natural language processing, synthetic text can be generated to expand the diversity of language models and improve their performance on tasks such as translation, summarization, and question answering.
As the AI industry continues to grapple with the challenge of data scarcity, data farming and synthetic data generation are likely to play increasingly important roles. By actively cultivating new data sources and leveraging the power of generative models, AI developers can ensure a steady supply of high-quality, diverse data to train and refine their models. This, in turn, will enable the creation of more advanced and capable AI systems that can tackle complex real-world problems and drive innovation across various domains.

## Why Web3

The Web2 synthetic data landscape is already populated with numerous well-funded companies. Gretel.ai raised $50 million, Tonic.ai secured $35 million, and Mostly.ai attracted $17 million in funding. However, existing synthetic data generation is primarily offered through Software as a Service (SaaS) platforms or standalone tooling. While these solutions provide value to individual users, they do not contribute to the creation of a more open and collaborative data ecosystem. The lack of incentives for data producers and consumers to share their infrastructure, workflows, and final datasets hinders the potential for widespread adoption and innovation in the field of synthetic data.

This is where Web3 technologies come into play. By leveraging the power of blockchain and decentralized networks, Web3 can align the incentives of various stakeholders and foster the development of an open synthetic data ecosystem. Decentralized platforms built on Web3 principles enable data producers and consumers to collaborate, share, and build upon each other's work in a transparent and trustless manner.

One notable example of this paradigm shift is the MIZU data network. By combining blockchain technology with large language models (LLMs), MIZU creates a fully open data layer that serves as the foundation for open-source AI development. In this network, all generated data and its corresponding ownership are trackable and verifiable on-chain. This level of transparency and immutability ensures that contributors are properly recognized and rewarded for their efforts.

Moreover, the composable nature of Web3 allows developers to build new pipelines and datasets on top of existing ones. This modular approach accelerates the creation and refinement of synthetic datasets, as developers can leverage the work of others and focus on adding value in their specific areas of expertise. The result is a vibrant and collaborative ecosystem where synthetic data is openly shared, improved, and utilized for the benefit of all participants.
